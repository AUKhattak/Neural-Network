{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "545894d0",
   "metadata": {},
   "source": [
    "## Task 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f0b193e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%matplotlib inline\n",
    "import numpy as np\n",
    "import scipy, matplotlib.pyplot as plt, IPython.display as ipd\n",
    "import librosa, librosa.display\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn  import preprocessing\n",
    "\n",
    "\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "# add this to ignore warnings from Librosa\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fd30fbfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for linear models \n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7723915b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "22ec5898",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tflearn in c:\\users\\p.choudhary\\anaconda3\\lib\\site-packages (0.5.0)\n",
      "Requirement already satisfied: six in c:\\users\\p.choudhary\\anaconda3\\lib\\site-packages (from tflearn) (1.16.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\p.choudhary\\anaconda3\\lib\\site-packages (from tflearn) (1.21.5)\n",
      "Requirement already satisfied: Pillow in c:\\users\\p.choudhary\\anaconda3\\lib\\site-packages (from tflearn) (9.0.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install tflearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ccfe0a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sdr_df = pd.read_csv('SDR_metadata.tsv', sep='\\t', header=0, index_col='Unnamed: 0')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "de7ef7f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>identifier</th>\n",
       "      <th>speaker</th>\n",
       "      <th>split</th>\n",
       "      <th>label</th>\n",
       "      <th>file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5_theo_23</td>\n",
       "      <td>theo</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>5</td>\n",
       "      <td>speech_data/5_theo_23.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2_yweweler_39</td>\n",
       "      <td>yweweler</td>\n",
       "      <td>TEST</td>\n",
       "      <td>2</td>\n",
       "      <td>speech_data/2_yweweler_39.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6_yweweler_34</td>\n",
       "      <td>yweweler</td>\n",
       "      <td>DEV</td>\n",
       "      <td>6</td>\n",
       "      <td>speech_data/6_yweweler_34.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6_yweweler_16</td>\n",
       "      <td>yweweler</td>\n",
       "      <td>DEV</td>\n",
       "      <td>6</td>\n",
       "      <td>speech_data/6_yweweler_16.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9_yweweler_2</td>\n",
       "      <td>yweweler</td>\n",
       "      <td>TEST</td>\n",
       "      <td>9</td>\n",
       "      <td>speech_data/9_yweweler_2.wav</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      identifier   speaker  split  label                           file\n",
       "0      5_theo_23      theo  TRAIN      5      speech_data/5_theo_23.wav\n",
       "1  2_yweweler_39  yweweler   TEST      2  speech_data/2_yweweler_39.wav\n",
       "2  6_yweweler_34  yweweler    DEV      6  speech_data/6_yweweler_34.wav\n",
       "3  6_yweweler_16  yweweler    DEV      6  speech_data/6_yweweler_16.wav\n",
       "4   9_yweweler_2  yweweler   TEST      9   speech_data/9_yweweler_2.wav"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sdr_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ba624d37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 5)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sdr_df[sdr_df.split == \"TRAIN\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1312372e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_wav_file = sdr_df.loc[sdr_df['identifier'] == '7_theo_0'].file[700]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6ed8b82e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                <audio  controls=\"controls\" >\n",
       "                    <source src=\"data:audio/wav;base64,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\" type=\"audio/wav\" />\n",
       "                    Your browser does not support the audio element.\n",
       "                </audio>\n",
       "              "
      ],
      "text/plain": [
       "<IPython.lib.display.Audio object>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# play and listen to a sample \n",
    "SAMPLING_RATE = 8000 # This value is determined by the wav file, DO NOT CHANGE\n",
    "\n",
    "x, sr = librosa.load(sample_wav_file, sr=SAMPLING_RATE) #, \n",
    "ipd.Audio(x, rate=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ae9884a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x144 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot as a waveform \n",
    "fig, ax = plt.subplots(figsize=(10, 2), sharex=True)\n",
    "\n",
    "img = librosa.display.waveshow(y=x, sr=sr, alpha=0.75, x_axis='time', color='blue')\n",
    "\n",
    "ax.set(title='Amplitude waveform')\n",
    "ax.set_ylabel('Amplitude')\n",
    "ax.label_outer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "994057a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_melspectrogram(signal, sr, num_mels):\n",
    "    \"\"\"\n",
    "    Given a time series speech signal (.wav), sampling rate (sr), \n",
    "    and the number of mel coefficients, return a mel-scaled \n",
    "    representation of the signal as numpy array.\n",
    "    \"\"\"\n",
    "    \n",
    "    mel_features = librosa.feature.melspectrogram(y=signal,\n",
    "        sr=sr,\n",
    "        n_fft=200, # with sampling rate = 8000, this corresponds to 25 ms\n",
    "        hop_length=80, # with sampling rate = 8000, this corresponds to 10 ms\n",
    "        n_mels=num_mels, # number of frequency bins, use either 13 or 39\n",
    "        fmin=50, # min frequency threshold\n",
    "        fmax=4000 # max frequency threshold, set to SAMPLING_RATE/2\n",
    "    )\n",
    "    \n",
    "    # for numerical stability added this line\n",
    "    mel_features = np.where(mel_features == 0, np.finfo(float).eps, mel_features)\n",
    "\n",
    "    # 20 * log10 to convert to log scale\n",
    "    log_mel_features = 20*np.log10(mel_features)\n",
    "\n",
    "    # feature scaling\n",
    "    scaled_log_mel_features = preprocessing.scale(log_mel_features, axis=1)\n",
    "    \n",
    "    return scaled_log_mel_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "00d6ac78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13, 43)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "melspectrogram = extract_melspectrogram(x, sr, num_mels=13)\n",
    "\n",
    "melspectrogram.shape\n",
    "# x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a57e48b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\p.choudhary\\anaconda3\\lib\\site-packages\\tensorflow\\python\\compat\\v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n",
      "curses is not supported on this machine (please install/reinstall curses for an optimal experience)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import random\n",
    "import tflearn\n",
    "import librosa\n",
    "import numpy as np\n",
    "import librosa.display\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f7ba64ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare data and split \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data = pd.read_csv('SDR_metadata.tsv', sep='\\t')\n",
    "\n",
    "\n",
    "\n",
    "train_data = data[data.split ==\"TRAIN\"]\n",
    "dev_data = data[data.split ==\"DEV\"]\n",
    "test_data = data[data.split ==\"TEST\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6330f290",
   "metadata": {},
   "source": [
    "## Preprocessing of Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1083cda4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nn_data(df):\n",
    "    signals = df.file.values\n",
    "    labels = df.label.values\n",
    "    # This value details is given in TASK 1 parameter N <= 25\n",
    "    # N=10   \n",
    "\n",
    "    signals1 = []\n",
    "    for file in df.file.values:\n",
    "        signal1, sr = librosa.load(file)\n",
    "        signals1.append(signal1)\n",
    "\n",
    "    return [extract_melspectrogram(s, sr=8000, num_mels=13) for s in signals1], labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f12e6ea1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-2.2741847  -1.3208863  -1.4830146  ... -0.81838155 -0.9981574\n",
      "  -1.4287398 ]\n",
      " [-1.0942035  -0.39628923 -0.7949283  ... -0.64620376 -0.7473365\n",
      "  -0.94756997]\n",
      " [-0.5984957  -0.17020981  0.34357923 ...  0.15686874  0.09897813\n",
      "  -0.23630676]\n",
      " ...\n",
      " [ 3.6494758   2.3761845  -0.41912842 ... -0.45667458  0.17729683\n",
      "   1.9654638 ]\n",
      " [ 3.8775768   2.616933   -0.42861995 ... -0.52657515  0.47307432\n",
      "   2.2103999 ]\n",
      " [ 4.0930676   2.8280146  -0.4012446  ... -0.52157     0.76714927\n",
      "   2.4917164 ]]\n"
     ]
    }
   ],
   "source": [
    "nn_train, train_labels = get_nn_data(train_data)\n",
    "print(nn_train[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "394f6bd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-2.2741847  -1.3208863  -1.4830146  ... -0.81838155 -0.9981574\n",
      "  -1.4287398 ]\n",
      " [-1.0942035  -0.39628923 -0.7949283  ... -0.64620376 -0.7473365\n",
      "  -0.94756997]\n",
      " [-0.5984957  -0.17020981  0.34357923 ...  0.15686874  0.09897813\n",
      "  -0.23630676]\n",
      " ...\n",
      " [ 3.6494758   2.3761845  -0.41912842 ... -0.45667458  0.17729683\n",
      "   1.9654638 ]\n",
      " [ 3.8775768   2.616933   -0.42861995 ... -0.52657515  0.47307432\n",
      "   2.2103999 ]\n",
      " [ 4.0930676   2.8280146  -0.4012446  ... -0.52157     0.76714927\n",
      "   2.4917164 ]]\n"
     ]
    }
   ],
   "source": [
    "print(nn_train[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0e3e1ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "num_classes = 10\n",
    "array=train_labels\n",
    "array=np.array(train_labels)\n",
    "labels = torch.from_numpy(train_labels)\n",
    "labels = F.one_hot(labels, num_classes)\n",
    "labels = labels.type(\"torch.FloatTensor\")\n",
    "\n",
    "\n",
    "max_len = 130\n",
    "\n",
    "rnn_train_data = []\n",
    "for sublist in nn_train:\n",
    "    x = sublist.shape\n",
    "#     print(\"x1\", x[1])\n",
    "#     print(\"max_len-x1\", max_len-x[1])\n",
    "    if x[1]> max_len:\n",
    "        #truncating here\n",
    "        padded_arr=sublist[:, :max_len]\n",
    "    else:\n",
    "        # for padding\n",
    "        padded_arr = np.pad(sublist, pad_width=((0,0),(0,max_len-x[1])), mode='constant')    \n",
    "    rnn_train_data.append(torch.transpose(torch.from_numpy(padded_arr), 0,1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "191ea818",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_train_data = torch.stack(rnn_train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1009189b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function Tensor.type>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rnn_train_data = torch.tensor(rnn_train_data)\n",
    "rnn_train_data.shape\n",
    "labels.type"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7387e945",
   "metadata": {},
   "source": [
    "## Data Loader for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "557ca6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class RNNTrainDataset(Dataset):\n",
    "    def __init__(self, rnn_train_data, labels):\n",
    "        self.rnn_train_data = rnn_train_data\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.rnn_train_data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.rnn_train_data[idx], self.labels[idx]\n",
    "\n",
    "batch_size = 20\n",
    "\n",
    "train_dataset = RNNTrainDataset(rnn_train_data, labels)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "417ef24a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0:\n",
      "Data: torch.Size([20, 130, 13]), -4.190584182739258, 7.196196556091309\n",
      "Target: torch.Size([20, 10])\n",
      "Batch 1:\n",
      "Data: torch.Size([20, 130, 13]), -4.218393325805664, 6.029603958129883\n",
      "Target: torch.Size([20, 10])\n",
      "Batch 2:\n",
      "Data: torch.Size([20, 130, 13]), -4.27483606338501, 6.438503742218018\n",
      "Target: torch.Size([20, 10])\n",
      "Batch 3:\n",
      "Data: torch.Size([20, 130, 13]), -3.718120574951172, 6.305238723754883\n",
      "Target: torch.Size([20, 10])\n",
      "Batch 4:\n",
      "Data: torch.Size([20, 130, 13]), -4.143735885620117, 6.898062229156494\n",
      "Target: torch.Size([20, 10])\n",
      "Batch 5:\n",
      "Data: torch.Size([20, 130, 13]), -4.593776702880859, 5.780646324157715\n",
      "Target: torch.Size([20, 10])\n",
      "Batch 6:\n",
      "Data: torch.Size([20, 130, 13]), -4.559310436248779, 6.084070205688477\n",
      "Target: torch.Size([20, 10])\n",
      "Batch 7:\n",
      "Data: torch.Size([20, 130, 13]), -3.9744558334350586, 6.0421624183654785\n",
      "Target: torch.Size([20, 10])\n",
      "Batch 8:\n",
      "Data: torch.Size([20, 130, 13]), -5.587302207946777, 6.433138847351074\n",
      "Target: torch.Size([20, 10])\n",
      "Batch 9:\n",
      "Data: torch.Size([20, 130, 13]), -4.707558631896973, 6.669035911560059\n",
      "Target: torch.Size([20, 10])\n",
      "Batch 10:\n",
      "Data: torch.Size([20, 130, 13]), -5.449426174163818, 7.533505439758301\n",
      "Target: torch.Size([20, 10])\n",
      "Batch 11:\n",
      "Data: torch.Size([20, 130, 13]), -3.2670931816101074, 5.817032337188721\n",
      "Target: torch.Size([20, 10])\n",
      "Batch 12:\n",
      "Data: torch.Size([20, 130, 13]), -3.805403232574463, 6.076083183288574\n",
      "Target: torch.Size([20, 10])\n",
      "Batch 13:\n",
      "Data: torch.Size([20, 130, 13]), -3.7109484672546387, 6.244644641876221\n",
      "Target: torch.Size([20, 10])\n",
      "Batch 14:\n",
      "Data: torch.Size([20, 130, 13]), -5.5107011795043945, 5.710450172424316\n",
      "Target: torch.Size([20, 10])\n",
      "Batch 15:\n",
      "Data: torch.Size([20, 130, 13]), -4.822391033172607, 6.251387119293213\n",
      "Target: torch.Size([20, 10])\n",
      "Batch 16:\n",
      "Data: torch.Size([20, 130, 13]), -4.22611665725708, 6.500782012939453\n",
      "Target: torch.Size([20, 10])\n",
      "Batch 17:\n",
      "Data: torch.Size([20, 130, 13]), -4.162663459777832, 6.407744884490967\n",
      "Target: torch.Size([20, 10])\n",
      "Batch 18:\n",
      "Data: torch.Size([20, 130, 13]), -3.8259592056274414, 6.375967979431152\n",
      "Target: torch.Size([20, 10])\n",
      "Batch 19:\n",
      "Data: torch.Size([20, 130, 13]), -3.733121633529663, 6.204093933105469\n",
      "Target: torch.Size([20, 10])\n",
      "Batch 20:\n",
      "Data: torch.Size([20, 130, 13]), -4.062880039215088, 6.220667362213135\n",
      "Target: torch.Size([20, 10])\n",
      "Batch 21:\n",
      "Data: torch.Size([20, 130, 13]), -4.34484338760376, 6.16820764541626\n",
      "Target: torch.Size([20, 10])\n",
      "Batch 22:\n",
      "Data: torch.Size([20, 130, 13]), -4.222121715545654, 6.700920581817627\n",
      "Target: torch.Size([20, 10])\n",
      "Batch 23:\n",
      "Data: torch.Size([20, 130, 13]), -4.664234638214111, 6.120275497436523\n",
      "Target: torch.Size([20, 10])\n",
      "Batch 24:\n",
      "Data: torch.Size([20, 130, 13]), -4.493012428283691, 6.452219009399414\n",
      "Target: torch.Size([20, 10])\n",
      "Batch 25:\n",
      "Data: torch.Size([20, 130, 13]), -6.372474670410156, 6.471863746643066\n",
      "Target: torch.Size([20, 10])\n",
      "Batch 26:\n",
      "Data: torch.Size([20, 130, 13]), -5.381558895111084, 5.872307300567627\n",
      "Target: torch.Size([20, 10])\n",
      "Batch 27:\n",
      "Data: torch.Size([20, 130, 13]), -3.905111312866211, 6.187506675720215\n",
      "Target: torch.Size([20, 10])\n",
      "Batch 28:\n",
      "Data: torch.Size([20, 130, 13]), -4.539839744567871, 5.994963645935059\n",
      "Target: torch.Size([20, 10])\n",
      "Batch 29:\n",
      "Data: torch.Size([20, 130, 13]), -5.200198173522949, 6.235659599304199\n",
      "Target: torch.Size([20, 10])\n",
      "Batch 30:\n",
      "Data: torch.Size([20, 130, 13]), -5.567558288574219, 6.442564010620117\n",
      "Target: torch.Size([20, 10])\n",
      "Batch 31:\n",
      "Data: torch.Size([20, 130, 13]), -3.918264865875244, 6.819457530975342\n",
      "Target: torch.Size([20, 10])\n",
      "Batch 32:\n",
      "Data: torch.Size([20, 130, 13]), -6.672732830047607, 6.87239933013916\n",
      "Target: torch.Size([20, 10])\n",
      "Batch 33:\n",
      "Data: torch.Size([20, 130, 13]), -4.2857465744018555, 6.493926048278809\n",
      "Target: torch.Size([20, 10])\n",
      "Batch 34:\n",
      "Data: torch.Size([20, 130, 13]), -4.831127166748047, 6.056735992431641\n",
      "Target: torch.Size([20, 10])\n",
      "Batch 35:\n",
      "Data: torch.Size([20, 130, 13]), -3.726179599761963, 6.3890380859375\n",
      "Target: torch.Size([20, 10])\n",
      "Batch 36:\n",
      "Data: torch.Size([20, 130, 13]), -3.8679234981536865, 5.8435235023498535\n",
      "Target: torch.Size([20, 10])\n",
      "Batch 37:\n",
      "Data: torch.Size([20, 130, 13]), -3.886268377304077, 6.192634105682373\n",
      "Target: torch.Size([20, 10])\n",
      "Batch 38:\n",
      "Data: torch.Size([20, 130, 13]), -3.5655901432037354, 6.2041802406311035\n",
      "Target: torch.Size([20, 10])\n",
      "Batch 39:\n",
      "Data: torch.Size([20, 130, 13]), -3.9252219200134277, 6.264621734619141\n",
      "Target: torch.Size([20, 10])\n",
      "Batch 40:\n",
      "Data: torch.Size([20, 130, 13]), -5.591846466064453, 6.317455291748047\n",
      "Target: torch.Size([20, 10])\n",
      "Batch 41:\n",
      "Data: torch.Size([20, 130, 13]), -3.7776849269866943, 6.518020153045654\n",
      "Target: torch.Size([20, 10])\n",
      "Batch 42:\n",
      "Data: torch.Size([20, 130, 13]), -4.044051170349121, 6.134025573730469\n",
      "Target: torch.Size([20, 10])\n",
      "Batch 43:\n",
      "Data: torch.Size([20, 130, 13]), -3.7981503009796143, 6.761226177215576\n",
      "Target: torch.Size([20, 10])\n",
      "Batch 44:\n",
      "Data: torch.Size([20, 130, 13]), -4.655122756958008, 6.708148002624512\n",
      "Target: torch.Size([20, 10])\n",
      "Batch 45:\n",
      "Data: torch.Size([20, 130, 13]), -4.211407661437988, 5.499555587768555\n",
      "Target: torch.Size([20, 10])\n",
      "Batch 46:\n",
      "Data: torch.Size([20, 130, 13]), -3.8630123138427734, 5.972314357757568\n",
      "Target: torch.Size([20, 10])\n",
      "Batch 47:\n",
      "Data: torch.Size([20, 130, 13]), -4.249297618865967, 6.507746696472168\n",
      "Target: torch.Size([20, 10])\n",
      "Batch 48:\n",
      "Data: torch.Size([20, 130, 13]), -3.7122485637664795, 7.097259521484375\n",
      "Target: torch.Size([20, 10])\n",
      "Batch 49:\n",
      "Data: torch.Size([20, 130, 13]), -3.1046149730682373, 6.296563625335693\n",
      "Target: torch.Size([20, 10])\n",
      "Batch 50:\n",
      "Data: torch.Size([20, 130, 13]), -4.937540531158447, 6.147575378417969\n",
      "Target: torch.Size([20, 10])\n",
      "Batch 51:\n",
      "Data: torch.Size([20, 130, 13]), -5.08383321762085, 6.09686803817749\n",
      "Target: torch.Size([20, 10])\n",
      "Batch 52:\n",
      "Data: torch.Size([20, 130, 13]), -4.138797760009766, 6.444220066070557\n",
      "Target: torch.Size([20, 10])\n",
      "Batch 53:\n",
      "Data: torch.Size([20, 130, 13]), -4.366615295410156, 6.643308162689209\n",
      "Target: torch.Size([20, 10])\n",
      "Batch 54:\n",
      "Data: torch.Size([20, 130, 13]), -3.7719027996063232, 6.051473617553711\n",
      "Target: torch.Size([20, 10])\n",
      "Batch 55:\n",
      "Data: torch.Size([20, 130, 13]), -4.237392902374268, 6.865937232971191\n",
      "Target: torch.Size([20, 10])\n",
      "Batch 56:\n",
      "Data: torch.Size([20, 130, 13]), -3.947420835494995, 6.004716396331787\n",
      "Target: torch.Size([20, 10])\n",
      "Batch 57:\n",
      "Data: torch.Size([20, 130, 13]), -4.528825759887695, 6.208702087402344\n",
      "Target: torch.Size([20, 10])\n",
      "Batch 58:\n",
      "Data: torch.Size([20, 130, 13]), -5.332313060760498, 6.2821784019470215\n",
      "Target: torch.Size([20, 10])\n",
      "Batch 59:\n",
      "Data: torch.Size([20, 130, 13]), -3.6955573558807373, 8.998211860656738\n",
      "Target: torch.Size([20, 10])\n",
      "Batch 60:\n",
      "Data: torch.Size([20, 130, 13]), -4.410855293273926, 6.076737880706787\n",
      "Target: torch.Size([20, 10])\n",
      "Batch 61:\n",
      "Data: torch.Size([20, 130, 13]), -6.2663679122924805, 5.891692638397217\n",
      "Target: torch.Size([20, 10])\n",
      "Batch 62:\n",
      "Data: torch.Size([20, 130, 13]), -3.7962756156921387, 6.389504432678223\n",
      "Target: torch.Size([20, 10])\n",
      "Batch 63:\n",
      "Data: torch.Size([20, 130, 13]), -4.856092929840088, 6.479170799255371\n",
      "Target: torch.Size([20, 10])\n",
      "Batch 64:\n",
      "Data: torch.Size([20, 130, 13]), -3.554659366607666, 6.122483253479004\n",
      "Target: torch.Size([20, 10])\n",
      "Batch 65:\n",
      "Data: torch.Size([20, 130, 13]), -3.642367362976074, 6.0436320304870605\n",
      "Target: torch.Size([20, 10])\n",
      "Batch 66:\n",
      "Data: torch.Size([20, 130, 13]), -4.225441932678223, 6.441905975341797\n",
      "Target: torch.Size([20, 10])\n",
      "Batch 67:\n",
      "Data: torch.Size([20, 130, 13]), -6.647913932800293, 6.252090930938721\n",
      "Target: torch.Size([20, 10])\n",
      "Batch 68:\n",
      "Data: torch.Size([20, 130, 13]), -5.426799297332764, 7.0459089279174805\n",
      "Target: torch.Size([20, 10])\n",
      "Batch 69:\n",
      "Data: torch.Size([20, 130, 13]), -4.550774574279785, 6.349723815917969\n",
      "Target: torch.Size([20, 10])\n",
      "Batch 70:\n",
      "Data: torch.Size([20, 130, 13]), -3.8504672050476074, 6.6638898849487305\n",
      "Target: torch.Size([20, 10])\n",
      "Batch 71:\n",
      "Data: torch.Size([20, 130, 13]), -3.949000120162964, 6.3495073318481445\n",
      "Target: torch.Size([20, 10])\n",
      "Batch 72:\n",
      "Data: torch.Size([20, 130, 13]), -3.685177803039551, 6.1234564781188965\n",
      "Target: torch.Size([20, 10])\n",
      "Batch 73:\n",
      "Data: torch.Size([20, 130, 13]), -5.237528324127197, 5.954066753387451\n",
      "Target: torch.Size([20, 10])\n",
      "Batch 74:\n",
      "Data: torch.Size([20, 130, 13]), -3.8392746448516846, 6.232996463775635\n",
      "Target: torch.Size([20, 10])\n",
      "Batch 75:\n",
      "Data: torch.Size([20, 130, 13]), -4.585940837860107, 6.192903518676758\n",
      "Target: torch.Size([20, 10])\n",
      "Batch 76:\n",
      "Data: torch.Size([20, 130, 13]), -4.034937858581543, 6.110855579376221\n",
      "Target: torch.Size([20, 10])\n",
      "Batch 77:\n",
      "Data: torch.Size([20, 130, 13]), -7.344451904296875, 5.995325088500977\n",
      "Target: torch.Size([20, 10])\n",
      "Batch 78:\n",
      "Data: torch.Size([20, 130, 13]), -5.910155296325684, 5.969528675079346\n",
      "Target: torch.Size([20, 10])\n",
      "Batch 79:\n",
      "Data: torch.Size([20, 130, 13]), -3.6801412105560303, 6.274107933044434\n",
      "Target: torch.Size([20, 10])\n",
      "Batch 80:\n",
      "Data: torch.Size([20, 130, 13]), -6.005764484405518, 6.504246234893799\n",
      "Target: torch.Size([20, 10])\n",
      "Batch 81:\n",
      "Data: torch.Size([20, 130, 13]), -3.8803021907806396, 6.236222743988037\n",
      "Target: torch.Size([20, 10])\n",
      "Batch 82:\n",
      "Data: torch.Size([20, 130, 13]), -3.7227766513824463, 6.5691986083984375\n",
      "Target: torch.Size([20, 10])\n",
      "Batch 83:\n",
      "Data: torch.Size([20, 130, 13]), -3.8867595195770264, 5.87439489364624\n",
      "Target: torch.Size([20, 10])\n",
      "Batch 84:\n",
      "Data: torch.Size([20, 130, 13]), -6.716172218322754, 6.854038238525391\n",
      "Target: torch.Size([20, 10])\n",
      "Batch 85:\n",
      "Data: torch.Size([20, 130, 13]), -5.911393642425537, 6.386351108551025\n",
      "Target: torch.Size([20, 10])\n",
      "Batch 86:\n",
      "Data: torch.Size([20, 130, 13]), -5.089744567871094, 6.503204345703125\n",
      "Target: torch.Size([20, 10])\n",
      "Batch 87:\n",
      "Data: torch.Size([20, 130, 13]), -4.896405220031738, 6.540771484375\n",
      "Target: torch.Size([20, 10])\n",
      "Batch 88:\n",
      "Data: torch.Size([20, 130, 13]), -3.8154258728027344, 6.396423816680908\n",
      "Target: torch.Size([20, 10])\n",
      "Batch 89:\n",
      "Data: torch.Size([20, 130, 13]), -3.853888511657715, 6.256023406982422\n",
      "Target: torch.Size([20, 10])\n",
      "Batch 90:\n",
      "Data: torch.Size([20, 130, 13]), -5.019634246826172, 6.263338565826416\n",
      "Target: torch.Size([20, 10])\n",
      "Batch 91:\n",
      "Data: torch.Size([20, 130, 13]), -6.770410537719727, 6.584115982055664\n",
      "Target: torch.Size([20, 10])\n",
      "Batch 92:\n",
      "Data: torch.Size([20, 130, 13]), -5.821545600891113, 6.2786478996276855\n",
      "Target: torch.Size([20, 10])\n",
      "Batch 93:\n",
      "Data: torch.Size([20, 130, 13]), -5.226327896118164, 6.652514934539795\n",
      "Target: torch.Size([20, 10])\n",
      "Batch 94:\n",
      "Data: torch.Size([20, 130, 13]), -6.668238639831543, 6.535574436187744\n",
      "Target: torch.Size([20, 10])\n",
      "Batch 95:\n",
      "Data: torch.Size([20, 130, 13]), -8.311408042907715, 6.580831050872803\n",
      "Target: torch.Size([20, 10])\n",
      "Batch 96:\n",
      "Data: torch.Size([20, 130, 13]), -7.597908973693848, 5.988559722900391\n",
      "Target: torch.Size([20, 10])\n",
      "Batch 97:\n",
      "Data: torch.Size([20, 130, 13]), -5.233835697174072, 5.986154556274414\n",
      "Target: torch.Size([20, 10])\n",
      "Batch 98:\n",
      "Data: torch.Size([20, 130, 13]), -4.565392017364502, 6.638792991638184\n",
      "Target: torch.Size([20, 10])\n",
      "Batch 99:\n",
      "Data: torch.Size([20, 130, 13]), -3.7406668663024902, 6.684789657592773\n",
      "Target: torch.Size([20, 10])\n"
     ]
    }
   ],
   "source": [
    "for batch_idx, (data, target) in enumerate(train_loader):\n",
    "    print(f\"Batch {batch_idx}:\")\n",
    "    print(f\"Data: {data.shape}, {data.min()}, {data.max()}\")\n",
    "    print(f\"Target: {target.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32525f64",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "75ec313d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hp\n",
    "num_epochs=100\n",
    "input_size = 13\n",
    "hidden_size = 128\n",
    "num_classes = 10\n",
    "learning_rate = 0.01\n",
    "n_total_steps = len(rnn_train_data)\n",
    "# num_layers=3\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f88d52d",
   "metadata": {},
   "source": [
    "## LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d20a7d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN1(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(RNN1, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        #self.rnn = nn.RNN(input_size, hidden_size)\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, bidirectional=True, batch_first=True) #if we want to run LSTM then we need to uncoment this line,and comnt abve line\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.fc = nn.Linear(hidden_size*2, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(2, 20, self.hidden_size, dtype=torch.float32)\n",
    "        c0 = torch.zeros(2, 20, self.hidden_size, dtype=torch.float32)\n",
    "        # out : seq_len x hidden_size\n",
    "        #out, _ = self.rnn(x, h0)\n",
    "        out, _ = self.lstm(x, (h0, c0))     #if we want to run LSTM then we need to uncoment this line, and coment above line\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        out_softmax = F.softmax(out)\n",
    "        return out, out_softmax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09721892",
   "metadata": {},
   "source": [
    "## Training loop that also plot loss graph and tsne plot for last out layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff9f2dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Step [100/100], Loss: 2.4111\n",
      "Train loss: 2.3468, Train accuracy: 0.1055\n",
      "Epoch [2/100], Step [100/100], Loss: 2.3611\n",
      "Train loss: 2.3611, Train accuracy: 0.1000\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "rnn3 = RNN1(input_size, hidden_size, num_classes)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(rnn3.parameters(), lr=learning_rate)\n",
    "\n",
    "# initialize an empty list to store the loss at each epoch\n",
    "loss_history = []\n",
    "features = []\n",
    "labels = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0.0\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "    \n",
    "    for i, (sample, label) in enumerate(train_loader):\n",
    "        # Forward pass\n",
    "        last_layer, out = rnn3(sample)\n",
    "        features.append(last_layer.detach().cpu().numpy())\n",
    "        labels.append(label.cpu().numpy())\n",
    "        loss = criterion(out, label)\n",
    "\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        total_correct += torch.sum(torch.argmax(out, dim=1) == torch.argmax(label, dim=1)).item()\n",
    "        total_samples += len(label)\n",
    "\n",
    "        if (i+1) % 100 == 0:\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(train_loader)}], Loss: {loss.item():.4f}')\n",
    "    \n",
    "    train_loss = total_loss / len(train_loader)\n",
    "    train_accuracy = total_correct / total_samples\n",
    "    loss_history.append(train_loss)  # append the loss at this epoch to the list\n",
    "    print(f'Train loss: {train_loss:.4f}, Train accuracy: {train_accuracy:.4f}')\n",
    "    \n",
    "    \n",
    "# plot the loss history\n",
    "plt.plot(loss_history)\n",
    "plt.title('Training loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()\n",
    "plt.savefig('Training_Loss.png')\n",
    "\n",
    "\n",
    "\n",
    "# # # Tsne Plot\n",
    "# from sklearn.manifold import TSNE\n",
    "# features = np.concatenate(features, axis=0)\n",
    "# labels = np.concatenate(labels, axis=0)\n",
    "\n",
    "# tsne = TSNE(n_components=2, random_state=42)\n",
    "# embedded_features = tsne.fit_transform(features)\n",
    "\n",
    "# # plot the embedded features with different colors for different labels\n",
    "# fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "# plt.scatter(embedded_features[:, 0], embedded_features[:, 1])\n",
    "# plt.colorbar()\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d972e772",
   "metadata": {},
   "outputs": [],
   "source": [
    "### for color TSNE plot\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "rnn3 = RNN1(input_size, hidden_size, num_classes)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(rnn3.parameters(), lr=learning_rate)\n",
    "\n",
    "# initialize an empty list to store the loss at each epoch\n",
    "loss_history = []\n",
    "features = []\n",
    "labels = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0.0\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "    \n",
    "    for i, (sample, label) in enumerate(train_loader):\n",
    "        # Forward pass\n",
    "        last_layer, out = rnn3(sample)\n",
    "        features.append(last_layer.detach().cpu().numpy())\n",
    "        labels.append(label.cpu().numpy())\n",
    "        loss = criterion(out, label)\n",
    "\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        total_correct += torch.sum(torch.argmax(out, dim=1) == torch.argmax(label, dim=1)).item()\n",
    "        total_samples += len(label)\n",
    "\n",
    "        if (i+1) % 100 == 0:\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(train_loader)}], Loss: {loss.item():.4f}')\n",
    "    \n",
    "    train_loss = total_loss / len(train_loader)\n",
    "    train_accuracy = total_correct / total_samples\n",
    "    loss_history.append(train_loss)  # append the loss at this epoch to the list\n",
    "    print(f'Train loss: {train_loss:.4f}, Train accuracy: {train_accuracy:.4f}')\n",
    "    \n",
    "# plot the loss history\n",
    "plt.plot(loss_history)\n",
    "plt.title('Training loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()\n",
    "plt.savefig('Training_Loss.png')\n",
    "\n",
    "# TSNE plot\n",
    "features = np.concatenate(features, axis=0)\n",
    "labels = np.concatenate(labels, axis=0)\n",
    "\n",
    "tsne = TSNE(n_components=2, random_state=42)\n",
    "embedded_features = tsne.fit_transform(features)\n",
    "\n",
    "# plot the embedded features with different colors for different labels\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "for i in range(num_classes):\n",
    "    # plot the points with label i in color i\n",
    "    plt.scatter(embedded_features[labels==i, 0], embedded_features[labels==i, 1], label=f'Class {i}')\n",
    "    \n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e6a93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdcf1d56",
   "metadata": {},
   "source": [
    "## for saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2962555",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(rnn3.state_dict(), 'LSTM_model_with_40%_t_ACC.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3e32a3d",
   "metadata": {},
   "source": [
    "## Dev Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0951fb89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare data and split \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data = pd.read_csv('SDR_metadata.tsv', sep='\\t')\n",
    "\n",
    "\n",
    "\n",
    "train_data = data[data.split ==\"TRAIN\"]\n",
    "dev_data = data[data.split ==\"DEV\"]\n",
    "test_data = data[data.split ==\"TEST\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab8fe32",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_data = data[data.split ==\"DEV\"]\n",
    "dev_data_eval, dev_labels =get_nn_data(train_data)\n",
    "\n",
    "# nn_train, train_labels = get_nn_data(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3912c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 10\n",
    "array_dev=dev_labels\n",
    "array_dev=np.array(dev_labels)\n",
    "rnn_dev_labels = torch.from_numpy(dev_labels)\n",
    "rnn_dev_labels = F.one_hot(rnn_dev_labels, num_classes)\n",
    "rnn_dev_labels = rnn_dev_labels.type(\"torch.FloatTensor\")\n",
    "print(len(rnn_dev_labels))\n",
    "\n",
    "max_len = 130\n",
    "\n",
    "rnn_dev_data = []\n",
    "for sublist in dev_data_eval:\n",
    "    x = sublist.shape\n",
    "    if x[1]> max_len:\n",
    "        #truncating here\n",
    "        padded_arr=sublist[:, :max_len]\n",
    "    else:\n",
    "        # for padding\n",
    "        padded_arr = np.pad(sublist, pad_width=((0,0),(0,max_len-x[1])), mode='constant')    \n",
    "    rnn_dev_data.append(torch.transpose(torch.from_numpy(padded_arr), 0,1))      \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4361cc7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_dev_data = torch.stack(rnn_dev_data)\n",
    "rnn_dev_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a3540c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "batch_size = 20\n",
    "\n",
    "dev_dataset = RNNTrainDataset(rnn_dev_data, rnn_dev_labels)\n",
    "dev_loader = DataLoader(dev_dataset, batch_size=batch_size, shuffle=True, drop_last=True )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51bfc62d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch_idx, (data, target) in enumerate(dev_loader):\n",
    "    print(f\"Batch {batch_idx}:\")\n",
    "    print(f\"Data: {data.shape}, {data.min()}, {data.max()}\")\n",
    "    print(f\"Target: {target.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8467219a",
   "metadata": {},
   "source": [
    "## Calculating the Dev set accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2289f059",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "rnn_testing = RNN1(input_size, hidden_size, num_classes)\n",
    "features = []\n",
    "labels = []\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    total_correct_dev = 0\n",
    "    total_samples_dev = 0\n",
    "    for i, (sample, label) in enumerate(dev_loader):\n",
    "        last_layer, out = rnn3(sample)\n",
    "        features.append(last_layer.cpu().numpy())\n",
    "        labels.append(label.cpu().numpy())\n",
    "\n",
    "        preds_dev = torch.argmax(out)\n",
    "        labels_class_dev = torch.argmax(rnn_dev_labels[i])\n",
    "        correct = (preds_dev == labels_class_dev)\n",
    "        total_correct_dev += torch.sum(torch.argmax(out, dim=1) == torch.argmax(label, dim=1)).item()\n",
    "        total_samples_dev += len(label)\n",
    "        \n",
    "    test_acc = total_correct_dev / total_samples_dev\n",
    "    print(total_correct_dev)\n",
    "    print(total_samples_dev)\n",
    "    print(f'dev accuracy: {test_acc *100:.4f} %')\n",
    "    \n",
    "features = np.concatenate(features, axis=0)\n",
    "labels = np.concatenate(labels, axis=0)\n",
    "\n",
    "tsne = TSNE(n_components=2, random_state=42)\n",
    "embedded_features = tsne.fit_transform(features)\n",
    "\n",
    "# plot the embedded features with different colors for different labels\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "plt.scatter(embedded_features[:, 0], embedded_features[:, 1])\n",
    "plt.colorbar()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a151f52a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "rnn_testing = RNN1(input_size, hidden_size, num_classes)\n",
    "features = []\n",
    "labels = []\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    total_correct_dev = 0\n",
    "    total_samples_dev = 0\n",
    "    for i, (sample, label) in enumerate(dev_loader):\n",
    "        last_layer, out = rnn3(sample)\n",
    "        features.append(last_layer.cpu().numpy())\n",
    "        labels.append(label.cpu().numpy())\n",
    "\n",
    "        preds_dev = torch.argmax(out)\n",
    "        labels_class_dev = torch.argmax(rnn_dev_labels[i])\n",
    "        correct = (preds_dev == labels_class_dev)\n",
    "        total_correct_dev += torch.sum(torch.argmax(out, dim=1) == torch.argmax(label, dim=1)).item()\n",
    "        total_samples_dev += len(label)\n",
    "        \n",
    "    test_acc = total_correct_dev / total_samples_dev\n",
    "    print(total_correct_dev)\n",
    "    print(total_samples_dev)\n",
    "    print(f'dev accuracy: {test_acc *100:.4f} %')\n",
    "    \n",
    "features = np.concatenate(features, axis=0)\n",
    "labels = np.concatenate(labels, axis=0)\n",
    "\n",
    "tsne = TSNE(n_components=2, random_state=42)\n",
    "embedded_features = tsne.fit_transform(features)\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "embedded_features = tsne.fit_transform(features)\n",
    "labels = np.argmax(labels, axis=1)\n",
    "\n",
    "# Reshape embedded_features to have a single dimension\n",
    "embedded_features = embedded_features.reshape(-1)\n",
    "\n",
    "# Create labels as a 1-dimensional array\n",
    "labels = labels.ravel()\n",
    "colors = 'r', 'g', 'b', 'c', 'm', 'y', 'k', 'w', 'orange', 'purple'\n",
    "plt.scatter(embedded_features[::2], embedded_features[1::2], c=labels)\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9348e7e8",
   "metadata": {},
   "source": [
    "### Confusion Matrix and Precision,Recall,F1-Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f93407de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "\n",
    "rnn_testing = RNN1(input_size, hidden_size, num_classes)\n",
    "\n",
    "with torch.no_grad():\n",
    "    total_correct_dev = 0\n",
    "    total_samples_dev = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    for i, (sample, label) in enumerate(dev_loader):\n",
    "        last_layer, out = rnn3(sample)\n",
    "\n",
    "        preds_dev = torch.argmax(out, dim=1)\n",
    "        labels_class_dev = torch.argmax(label, dim=1)\n",
    "        \n",
    "        all_preds.extend(preds_dev.cpu().numpy())\n",
    "        all_labels.extend(labels_class_dev.cpu().numpy())\n",
    "        \n",
    "        total_correct_dev += torch.sum(preds_dev == labels_class_dev).item()\n",
    "        total_samples_dev += len(label)\n",
    "        \n",
    "    dev_acc = total_correct_dev / total_samples_dev\n",
    "    print(total_correct_dev)\n",
    "    print(total_samples_dev)\n",
    "    print(f'dev accuracy: {dev_acc *100:.4f} %')\n",
    "    \n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "#   print('Confusion matrix on Dev set:\\n', cm)\n",
    "    print('Confusion matrix on Dev set:\\n')\n",
    "    sns.heatmap(cm, annot=True, fmt='d')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.ylabel('True label')\n",
    "    plt.show()\n",
    "    \n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "overall_f1 = f1_score(all_labels, all_preds, average='macro')\n",
    "overall_precision = precision_score(all_labels, all_preds, average='macro')\n",
    "overall_recall = recall_score(all_labels, all_preds, average='macro')\n",
    "\n",
    "print('Confusion matrix on Dev set:\\n', cm)\n",
    "print('Overall F1-score:', overall_f1)\n",
    "print('Overall precision:', overall_precision)\n",
    "print('Overall recall:', overall_recall)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9facf96b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, f1_score, precision_score, recall_score\n",
    "\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "overall_f1 = f1_score(all_labels, all_preds, average='macro')\n",
    "overall_precision = precision_score(all_labels, all_preds, average='macro')\n",
    "overall_recall = recall_score(all_labels, all_preds, average='macro')\n",
    "\n",
    "print('Confusion matrix on Dev set:\\n', cm)\n",
    "print('Overall F1-score:', overall_f1)\n",
    "print('Overall precision:', overall_precision)\n",
    "print('Overall recall:', overall_recall)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "145a9124",
   "metadata": {},
   "source": [
    "# Test set Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92abc10d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare data and split \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data = pd.read_csv('SDR_metadata.tsv', sep='\\t')\n",
    "\n",
    "\n",
    "\n",
    "train_data = data[data.split ==\"TRAIN\"]\n",
    "dev_data = data[data.split ==\"DEV\"]\n",
    "test_data = data[data.split ==\"TEST\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba74f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = data[data.split ==\"TEST\"]\n",
    "test_data_eval, test_labels =get_nn_data(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34ab6342",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 10\n",
    "array_test=test_labels\n",
    "array_test=np.array(test_labels)\n",
    "rnn_test_labels = torch.from_numpy(test_labels)\n",
    "rnn_test_labels = F.one_hot(rnn_test_labels, num_classes)\n",
    "rnn_test_labels = rnn_test_labels.type(\"torch.FloatTensor\")\n",
    "print(len(rnn_test_labels))\n",
    "\n",
    "max_len = 130\n",
    "\n",
    "rnn_test_data = []\n",
    "for sublist in test_data_eval:\n",
    "    x = sublist.shape\n",
    "    \n",
    "   \n",
    "    if x[1]> max_len:\n",
    "        #truncating here\n",
    "        padded_arr=sublist[:, :max_len]\n",
    "    else:\n",
    "        # for padding\n",
    "        padded_arr = np.pad(sublist, pad_width=((0,0),(0,max_len-x[1])), mode='constant')    \n",
    "    rnn_test_data.append(torch.transpose(torch.from_numpy(padded_arr), 0,1))\n",
    "\n",
    "    \n",
    "\n",
    "# rnn_train_data = torch.stack(rnn_train_data)\n",
    "        \n",
    "\n",
    "rnn_dev_data[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a678034",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_test_data = torch.stack(rnn_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e725c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "771a0e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "batch_size = 20\n",
    "\n",
    "test_dataset = RNNTrainDataset(rnn_test_data, rnn_test_labels)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True, drop_last=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e030a223",
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch_idx, (data, target) in enumerate(test_loader):\n",
    "    print(f\"Batch {batch_idx}:\")\n",
    "    print(f\"Data: {data.shape}, {data.min()}, {data.max()}\")\n",
    "    print(f\"Target: {target.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f70f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_testing = RNN1(input_size, hidden_size, num_classes)\n",
    "features = []\n",
    "labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    total_correct_test = 0\n",
    "    total_samples_test = 0\n",
    "    for i, (sample, label) in enumerate(test_loader):\n",
    "        last_layer, out = rnn3(sample)\n",
    "        features.append(last_layer.cpu().numpy())\n",
    "        labels.append(label.cpu().numpy())\n",
    "        preds_test = torch.argmax(out)\n",
    "        labels_class_test = torch.argmax(rnn_test_labels[i])\n",
    "        correct = (preds_test == labels_class_test)\n",
    "        total_correct_test += torch.sum(torch.argmax(out, dim=1) == torch.argmax(label, dim=1)).item()\n",
    "        total_samples_test += len(label)\n",
    "        \n",
    "    test_acc = total_correct_test / total_samples_test\n",
    "    print(total_correct_test)\n",
    "    print(total_samples_test)\n",
    "    print(f'test accuracy: {test_acc *100:.4f} %')\n",
    "    \n",
    "features = np.concatenate(features, axis=0)\n",
    "labels = np.concatenate(labels, axis=0)\n",
    "\n",
    "tsne = TSNE(n_components=2, random_state=42)\n",
    "embedded_features = tsne.fit_transform(features)\n",
    "\n",
    "# plot the embedded features with different colors for different labels\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "plt.scatter(embedded_features[:, 0], embedded_features[:, 1])\n",
    "plt.title('TSNe for test Classification')\n",
    "plt.colorbar()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b74b4e8f",
   "metadata": {},
   "source": [
    "## confusion matrix and classification report\n",
    "## Evaluate your (best) neural models and compare to the baseline model using the same evalution process as in task I.4. (task 2.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c5f863f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "rnn_testing = RNN1(input_size, hidden_size, num_classes)\n",
    "\n",
    "with torch.no_grad():\n",
    "    total_correct_test = 0\n",
    "    total_samples_test = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    for i, (sample, label) in enumerate(test_loader):\n",
    "        last_layer, out = rnn3(sample)\n",
    "\n",
    "        preds_test = torch.argmax(out, dim=1)\n",
    "        labels_class_test = torch.argmax(label, dim=1)\n",
    "        \n",
    "        all_preds.extend(preds_test.cpu().numpy())\n",
    "        all_labels.extend(labels_class_test.cpu().numpy())\n",
    "        \n",
    "        total_correct_test += torch.sum(preds_test == labels_class_test).item()\n",
    "        total_samples_test += len(label)\n",
    "        \n",
    "    test_acc = total_correct_test / total_samples_test\n",
    "    print(total_correct_test)\n",
    "    print(total_samples_test)\n",
    "    print(f'test accuracy: {test_acc *100:.4f} %')\n",
    "    \n",
    "    # Compute confusion matrix\n",
    "    cm_test = confusion_matrix(all_labels, all_preds)\n",
    "    print('Confusion matrix for test Set:\\n')\n",
    "    sns.heatmap(cm_test, annot=True, fmt='d')\n",
    "    \n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "overall_f1 = f1_score(all_labels, all_preds, average='macro')\n",
    "overall_precision = precision_score(all_labels, all_preds, average='macro')\n",
    "overall_recall = recall_score(all_labels, all_preds, average='macro')\n",
    "\n",
    "print('Confusion matrix on Test set:\\n', cm)\n",
    "print('Overall F1-score:', overall_f1)\n",
    "print('Overall precision:', overall_precision)\n",
    "print('Overall recall:', overall_recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4deb4eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_parameters = filter(lambda p: p.requires_grad, rnn3.parameters())\n",
    "params = sum([np.prod(p.size()) for p in model_parameters])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ac988b",
   "metadata": {},
   "outputs": [],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce58fa75",
   "metadata": {},
   "source": [
    "## Statistical test (p_value)------ (Bootstrapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9fb6700",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data as data_utils\n",
    "\n",
    "# convert test data to PyTorch tensors\n",
    "test_data_eval_tensor =rnn_test_data\n",
    "test_labels_tensor = rnn_test_labels\n",
    "\n",
    "# create a WeightedRandomSampler with replacement\n",
    "sampler = data_utils.WeightedRandomSampler(weights=torch.ones(len(test_data_eval_tensor)), num_samples=len(test_data_eval_tensor), replacement=True)\n",
    "\n",
    "# create a DataLoader with the sampler\n",
    "test_loader_bootstrap = data_utils.DataLoader(dataset=data_utils.TensorDataset(test_data_eval_tensor, test_labels_tensor), batch_size=batch_size, sampler=sampler,drop_last=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc74cb3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "\n",
    "# Define the number of bootstrap samples\n",
    "num_bootstraps = 1000\n",
    "samp=0\n",
    "# Create a list to store the accuracy values for each bootstrap sample\n",
    "bootstrapped_accs = []\n",
    "\n",
    "# Define the RNN model\n",
    "rnn_testing = RNN1(input_size, hidden_size, num_classes)\n",
    "\n",
    "# Iterate over the specified number of bootstrap samples\n",
    "for i in range(num_bootstraps):\n",
    "    # Create a new DataLoader object using a WeightedRandomSampler to sample with replacement from the test data\n",
    "    sampler = torch.utils.data.WeightedRandomSampler(weights=torch.ones(len(test_data_eval_tensor)), num_samples=len(test_data_eval_tensor), replacement=True)\n",
    "    test_loader_bootstrap = torch.utils.data.DataLoader(dataset=torch.utils.data.TensorDataset(test_data_eval_tensor, test_labels_tensor), batch_size=batch_size, sampler=sampler, drop_last=True)\n",
    "    samp++i\n",
    "    with torch.no_grad():\n",
    "        total_correct_test = 0\n",
    "        total_samples_test = 0\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "        for i, (sample, label) in enumerate(test_loader_bootstrap):\n",
    "            last_layer, out = rnn3(sample)\n",
    "\n",
    "            preds_test = torch.argmax(out, dim=1)\n",
    "            labels_class_test = torch.argmax(label, dim=1)\n",
    "\n",
    "            all_preds.extend(preds_test.cpu().numpy())\n",
    "            all_labels.extend(labels_class_test.cpu().numpy())\n",
    "\n",
    "            total_correct_test += torch.sum(preds_test == labels_class_test).item()\n",
    "            total_samples_test += len(label)\n",
    "        test_acc = total_correct_test / total_samples_test\n",
    "        bootstrapped_accs.append(test_acc)\n",
    "\n",
    "# Compute the mean and standard deviation of the accuracy values across all bootstrap samples\n",
    "mean_acc = sum(bootstrapped_accs) / num_bootstraps\n",
    "std_acc = np.std(bootstrapped_accs)\n",
    "\n",
    "print(f'Mean accuracy: {mean_acc * 100:.4f} %')\n",
    "print(f'Standard deviation: {std_acc:.4f}')\n",
    "\n",
    "# Compute confusion matrix\n",
    "cm_test = confusion_matrix(all_labels, all_preds)\n",
    "print('Confusion matrix for test Set:\\n')\n",
    "sns.heatmap(cm_test, annot=True, fmt='d')\n",
    "\n",
    "# Compute precision, recall, F1-score\n",
    "report = classification_report(all_labels, all_preds)\n",
    "print('Classification report:\\n', report)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c1af0ee",
   "metadata": {},
   "source": [
    "## Significance Test (Task 2.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4caba405",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Set up the data\n",
    "rnn_mean_acc = 0.440736  # this value is calculated using bootstrap in Task no.2 \n",
    "rnn_std_acc = 0.0219     # this value is calculated using bootstrap in Task no.1\n",
    "linear_mean_acc = 0.0995924453280318\n",
    "linear_std_acc = 0.023840615328288208\n",
    "\n",
    "# Calculate the difference in mean accuracy between the two models\n",
    "mean_diff = rnn_mean_acc - linear_mean_acc\n",
    "\n",
    "# Concatenate the accuracy values for both models\n",
    "combined_acc = np.concatenate((np.random.normal(rnn_mean_acc, rnn_std_acc, size=1000), \n",
    "                               np.random.normal(linear_mean_acc, linear_std_acc, size=1000)))\n",
    "\n",
    "# Generate bootstrap samples and calculate mean accuracy differences\n",
    "n_bootstrap = 1000\n",
    "bootstrap_diff = np.zeros(n_bootstrap)\n",
    "for i in range(n_bootstrap):\n",
    "    resampled_acc = np.random.choice(combined_acc, size=len(combined_acc), replace=True)\n",
    "    rnn_mean = np.mean(resampled_acc[:1000])\n",
    "    linear_mean = np.mean(resampled_acc[1000:])\n",
    "    bootstrap_diff[i] = rnn_mean - linear_mean\n",
    "\n",
    "# Calculate the p-value\n",
    "p_value = np.mean(bootstrap_diff >= mean_diff)\n",
    "\n",
    "# Print the results\n",
    "print(\"Mean difference between RNN and linear regression models: {:.4f}\".format(mean_diff))\n",
    "print(\"p-value: {:.4f}\".format(p_value))\n",
    "if p_value < 0.05:\n",
    "    print(\"The difference between the mean accuracy of the RNN and linear regression models is statistically significant.\")\n",
    "else:\n",
    "    print(\"There is no statistically significant difference between the mean accuracy of the RNN and linear regression models.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
